{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKUoyHT7umwA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms,datasets,models\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "import urllib.request as request"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    def __init__(self):\n",
        "        self.ROOT_DATA_DIR = \"hymenoptera\"\n",
        "        self.EPOCH = 10\n",
        "        self.BATCH_SIZE = 32\n",
        "        self.LEARNING_RATE = 0.01\n",
        "        self.IMAGE_SIZE  = (224 , 224)\n",
        "        self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"this notebook is using: {self.DEVICE}\")\n",
        "        self.SEED = 205 \n",
        "      \n",
        "    def create_dir(self,dir_path):\n",
        "      os.makedirs(dir_path,exist_ok=True)\n",
        "      print(f'{dir_path} directory is created')\n",
        "config = config()"
      ],
      "metadata": {
        "id": "vpTxropOuuvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download Data"
      ],
      "metadata": {
        "id": "ncT7BFTPu6x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = 'https://download.pytorch.org/tutorial/hymenoptera_data.zip'"
      ],
      "metadata": {
        "id": "JMXXuMRdu1qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config.create_dir(dir_path=config.ROOT_DATA_DIR)\n",
        "\n",
        "data_zip_file = \"data.zip\"\n",
        "data_file_path = os.path.join(config.ROOT_DATA_DIR,data_zip_file)\n",
        "\n",
        "request.urlretrieve(data_url,data_file_path)"
      ],
      "metadata": {
        "id": "k7fwgL6JvAq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "def unzip_file(source: str, dest: str) -> None:\n",
        "    print(f\"extraction started...\")\n",
        "\n",
        "    with ZipFile(source, \"r\") as zip_f:\n",
        "        zip_f.extractall(dest)\n",
        "    print(f\"extracted {source} to {dest}\")\n",
        "\n",
        "unzip_file(data_file_path,config.ROOT_DATA_DIR)"
      ],
      "metadata": {
        "id": "M6LmD28rvEqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Path"
      ],
      "metadata": {
        "id": "nrZqPsSRvNQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "Path('/content/hymenoptera/hymenoptera_data/train')"
      ],
      "metadata": {
        "id": "cZXyWAAdvJ-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = Path('/content/hymenoptera/hymenoptera_data/train')\n",
        "test_path = Path('/content/hymenoptera/hymenoptera_data/val')"
      ],
      "metadata": {
        "id": "tBFFjx7Ovzf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Normalize the size of Image ,concept are used many places\n",
        "\n",
        "Mean of  each channel images\n",
        "\n",
        "for 28x28 image size\n",
        "\n",
        "mean = sum(value of pixel)/784 {28x28}\n",
        "\n",
        "std = \n",
        "\n",
        "(data-mean)/std"
      ],
      "metadata": {
        "id": "XjJjUrKuxIZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = torch.tensor([0.5,0.5,0.5])\n",
        "std = torch.tensor([0.5,0.5,0.5])"
      ],
      "metadata": {
        "id": "PwYqELTS16-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform the image"
      ],
      "metadata": {
        "id": "buqnPB4z4e49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_transform  = transforms.Compose([\n",
        "                                        transforms.Resize(config.IMAGE_SIZE),\n",
        "                                        transforms.RandomRotation(degrees=20),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)\n",
        "\n",
        "])\n",
        "\n",
        "test_transform  = transforms.Compose([\n",
        "                                          transforms.Resize(config.IMAGE_SIZE),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize(mean,std)\n",
        "\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "LkRWuXxiwEZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Featch Data From Local\n",
        "train_data = datasets.ImageFolder(root=train_path,transform=train_transform)\n",
        "test_data = datasets.ImageFolder(root=test_path,transform=test_transform)"
      ],
      "metadata": {
        "id": "CHHGlRqs0q6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping Features\n",
        "label_map = train_data.class_to_idx\n",
        "label_map"
      ],
      "metadata": {
        "id": "A4-s4g5l3ThB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data  # Describe the data "
      ],
      "metadata": {
        "id": "efTRc-123g6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader"
      ],
      "metadata": {
        "id": "HbAMnmsZ45aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "                               dataset= train_data,\n",
        "                               batch_size = config.BATCH_SIZE,\n",
        "                               shuffle=True\n",
        "                                )\n",
        "\n",
        "test_loader = DataLoader(\n",
        "                               dataset= test_data,\n",
        "                               batch_size = config.BATCH_SIZE,\n",
        "                               shuffle=False\n",
        "                                )"
      ],
      "metadata": {
        "id": "72nTHzT-387G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_loader))\n",
        "len(data)"
      ],
      "metadata": {
        "id": "bjNbrydD5Wpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images,label = data"
      ],
      "metadata": {
        "id": "GOHXxq-35bJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images.shape , label.shape # 32 is batch_size , 3 is RGB Channel , 28x28 is image size -----label is 32 bcoz of batch_size"
      ],
      "metadata": {
        "id": "b0SeUJYX5zxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visulzize the image"
      ],
      "metadata": {
        "id": "qbjZrO236day"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = images[0]\n",
        "img.shape"
      ],
      "metadata": {
        "id": "qsuQr4n465vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (3,224,224) convert into ----------> (224,224,3)\n",
        "plt.imshow(img.permute(1,2,0))"
      ],
      "metadata": {
        "id": "61sPMtbr53dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download use pre Trained Model for transfer learning (Alexnet)"
      ],
      "metadata": {
        "id": "jtodFaRC8YvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.alexnet(pretrained=True)    #Imagenet dataset 1000 no of classification image will be use"
      ],
      "metadata": {
        "id": "XLouZ3o76sOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)  # To See the Archetecture of models"
      ],
      "metadata": {
        "id": "rZEMPYvEDU_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why we using this pretrained models?\n",
        "if we have that model which already trained 1000 no of images i.e already seems so many features "
      ],
      "metadata": {
        "id": "_e4zhzAQE1NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count No. of Trained Parameter "
      ],
      "metadata": {
        "id": "AhfQpM2gFtnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_params(model):\n",
        "  model_params = {\"Modules\": list(), \"Parameters\": list()}\n",
        "  total = {\"trainable\": 0, \"non_trainable\": 0} \n",
        "  for name, parameters in model.named_parameters():\n",
        "    param = parameters.numel()\n",
        "    if not parameters.requires_grad:\n",
        "      total[\"non_trainable\"] += param\n",
        "      continue\n",
        "    model_params[\"Modules\"].append(name)\n",
        "    model_params[\"Parameters\"].append(param)\n",
        "    total[\"trainable\"] += param\n",
        "  df = pd.DataFrame(model_params)\n",
        "  df = df.style.set_caption(f\"Total parameters: {total}\")\n",
        "  return df\n",
        "\n",
        "count_params(model)"
      ],
      "metadata": {
        "id": "8AyWDQneDkM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Convert Trainable to Non-Trainable"
      ],
      "metadata": {
        "id": "tUiq4hKdLdOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# next(iter(model.parameters()))"
      ],
      "metadata": {
        "id": "9rZhUkXnIvOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (but we dont want make them trainable so this weight is update i.e they take a lot of time)\n",
        "# So We Freeze all the model Layers\n",
        "\n",
        "for parameters in model.parameters():\n",
        "  parameters.requires_grad = False  # meaning of requires_grad is ready for back propogation,\n",
        "                                    # that is calculating the gradient at every steps after that they go for optimizer step ,\n",
        "                                    # it will do the gradient descent\n"
      ],
      "metadata": {
        "id": "GYajYSgXF2NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_params(model)"
      ],
      "metadata": {
        "id": "RsmwCsW_IxoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create our own Classifier by using alexnet"
      ],
      "metadata": {
        "id": "HGv43dK_LuQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "id": "2pu0nnfhLQM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=9216, out_features=100 , bias=True),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5,inplace=False),\n",
        "    nn.Linear(in_features=100,out_features=2,bias=True) # out_feature=2 bcoz we have two features\n",
        ")"
      ],
      "metadata": {
        "id": "H4AVwvO2MA56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "hhwnAW2zOozA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_params(model)"
      ],
      "metadata": {
        "id": "YKFYnKG3PEYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training Loop"
      ],
      "metadata": {
        "id": "i7cq8SIgWUWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(config.DEVICE)"
      ],
      "metadata": {
        "id": "ZP1t4C3UPaV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "TLTQ5p2eW08w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(config.EPOCH):\n",
        "  with tqdm(train_loader) as tqdm_epoch:\n",
        "    for images,label in tqdm_epoch:\n",
        "      tqdm_epoch.set_description(f\"Epoch {epoch +1}/{config.EPOCH}\")\n",
        "\n",
        "      #put the images on device\n",
        "      images = images.to(config.DEVICE)\n",
        "      label = label.to(config.DEVICE)\n",
        "\n",
        "      #Forward pass\n",
        "      outputs =model(images)\n",
        "      loss = criterion(outputs,label)  #passing the pred and targets\n",
        "\n",
        "       #Backward Pass \n",
        "      optimizer.zero_grad() # reset the weight/gradient to zero or past gradient\n",
        "      loss.backward() #calculate the gradient\n",
        "      optimizer.step() # weight update\n",
        "\n",
        "      tqdm_epoch.set_postfix(loss=loss.item())\n",
        "\n",
        "#it just applying on classifier part and  frozen above part(not be calculated any gradient for feature or above part)\n",
        "# (classifier): Sequential(\n",
        "#     (0): Linear(in_features=9216, out_features=100, bias=True)\n",
        "#     (1): ReLU(inplace=True)\n",
        "#     (2): Dropout(p=0.5, inplace=False)\n",
        "#     (3): Linear(in_features=100, out_features=2, bias=True)"
      ],
      "metadata": {
        "id": "gVOXTNfgXT0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the model"
      ],
      "metadata": {
        "id": "h6fBrkcs4XdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('model_dir', exist_ok=True)\n",
        "model_file = os.path.join('model_dir','CNN_model.pth')\n",
        "torch.save(model,model_file)"
      ],
      "metadata": {
        "id": "0YCYs91BYF2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evalute the model"
      ],
      "metadata": {
        "id": "-eV773zA45kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.array([])\n",
        "target = np.array([])\n",
        "\n",
        "with torch.no_grad():  #Now no gradient are update for prediction, all gradient are frozen\n",
        "  for batch,data in enumerate(test_loader): # enmurate doing first show index/sequence value and second the data\n",
        "    images = data[0].to(config.DEVICE)  \n",
        "    label = data[1].to(config.DEVICE) \n",
        "\n",
        "    y_pred = model(images)\n",
        "\n",
        "\n",
        "    \n",
        "    pred = np.concatenate((pred , torch.argmax(y_pred,1).cpu().numpy()))\n",
        "    target = np.concatenate((target,label.cpu().numpy()))\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "wB099_SS4f80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(target,pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "3TLwwN0Y5TCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map"
      ],
      "metadata": {
        "id": "HENEst3B6Gsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(cm , annot=True , fmt='d', xticklabels=label_map.keys() , yticklabels= label_map.keys(), cbar=False)"
      ],
      "metadata": {
        "id": "ElfNGYhJ6Jry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prediction"
      ],
      "metadata": {
        "id": "eQ_Kdbqp64Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(test_loader))\n",
        "data"
      ],
      "metadata": {
        "id": "JqoLlO6c6YsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "qvmV4D5I68uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images,labels = data"
      ],
      "metadata": {
        "id": "yq7E--vC7UCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "id": "jXXS_7MI7ltR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = images[0]\n",
        "img"
      ],
      "metadata": {
        "id": "aEZu7yKf7qFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 2\n",
        "img = images[idx]\n",
        "img.shape\n",
        "plt.imshow(img.permute(1,2,0))"
      ],
      "metadata": {
        "id": "it2SwiRl7sE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = labels[idx]\n",
        "label_map[label.item()]"
      ],
      "metadata": {
        "id": "C7cOU_gJ8G7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.unsqueeze(dim=1)"
      ],
      "metadata": {
        "id": "8KFtkFfh8cNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_on_gpu = img.unsqueeze(0).to(config.DEVICE)\n",
        "\n",
        "pred_prob = F.softmax(model(img_on_gpu),dim=1)\n",
        "pred_prob\n"
      ],
      "metadata": {
        "id": "wxaHlH7j9JHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "argmax = torch.argmax(pred_prob).item()\n",
        "argmax"
      ],
      "metadata": {
        "id": "zE8WhEWV_CYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_label_map = {val : key for key,val in label_map.items()}\n",
        "inv_label_map"
      ],
      "metadata": {
        "id": "76okRtBgA6gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_label_map[argmax] , inv_label_map[labels[2].item()]"
      ],
      "metadata": {
        "id": "F0hYeGb3_0QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create prediction function"
      ],
      "metadata": {
        "id": "Xqjb-r2ZCWdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(data,model,label_map,device,idx=0):\n",
        "  images,labels = data\n",
        "\n",
        "  img = images[idx]\n",
        "  label = labels[idx]\n",
        "\n",
        "  plt.imshow(img.permute(1,2,0))\n",
        "  img_on_gpu = img.unsqueeze(0).to(config.DEVICE)\n",
        "  pred_prob = F.softmax(model(img_on_gpu),dim=1)\n",
        "  argmax = torch.argmax(pred_prob).item()\n",
        "\n",
        "  predicted_label = label_map[argmax]\n",
        "  actual_label = label_map[label.item()]\n",
        "\n",
        "  plt.title(f'actual : {actual_label} | predicted : {predicted_label}')\n",
        "  plt.axis('off')\n",
        "  return actual_label , predicted_label"
      ],
      "metadata": {
        "id": "l6v5MfGsCKJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(data,model,inv_label_map,config.DEVICE,idx=2)"
      ],
      "metadata": {
        "id": "RfTJvrY6CkGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Mhasd_BCrFc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}